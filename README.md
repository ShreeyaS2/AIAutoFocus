# FOCUSR â€” AI Smart AutoFocus (Web Edition)

Real-time browser-based subject tracking and background bokeh.  
The browser captures video (webcam or uploaded file), streams frames to a
Python backend over WebSocket, and displays AI-processed output live.

---

## ğŸ“ Project Structure

```
smart_autofocus_web/
â”œâ”€â”€ app.py              # FastAPI server + WebSocket pipeline
â”œâ”€â”€ detector.py         # YOLOv8 object detector
â”œâ”€â”€ tracker.py          # OpenCV CSRT tracker
â”œâ”€â”€ segmenter.py        # MediaPipe / GrabCut mask generation
â”œâ”€â”€ renderer.py         # Bokeh compositing & HUD
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html      # Full browser frontend (zero dependencies)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

```bash
# 1. Create & activate virtual environment
python -m venv venv
source venv/bin/activate          # Windows: venv\Scripts\activate

# 2. Install all dependencies
pip install -r requirements.txt

# 3. (Optional) GPU support â€” NVIDIA CUDA 11.8+
pip uninstall torch torchvision -y
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

The YOLOv8 model (`yolov8n.pt`, ~6 MB) downloads automatically on first run.

---

## ğŸš€ Running

```bash
python app.py
# or
uvicorn app:app --host 0.0.0.0 --port 8000
```

Then open your browser at **http://localhost:8000**

---

## ğŸ–¥ï¸ How to Use

1. **Open** `http://localhost:8000` in Chrome / Edge / Firefox.
2. **Choose a source**:
   - Click **â—‰ Webcam** to use your camera.
   - Click **â¬† Upload Video** to select an `.mp4` / `.mov` file.
   - Or **drag & drop** a video file onto the window.
3. **Hover** the cursor over the video â€” objects are highlighted with a
   preview box as you move the mouse.
4. **Click** on any highlighted object to **lock focus** â€” it stays sharp
   while the background blurs.
5. **Click again** on a different object to instantly **switch focus**.
6. Use the **sidebar controls** to:
   - Toggle low-light enhancement.
   - Adjust bokeh blur intensity.
   - Change detection interval (speed vs. accuracy trade-off).
7. **Keyboard shortcuts**:
   - `Space` â€” pause / resume
   - `Escape` â€” release lock
   - `W` â€” switch to webcam

---

## ğŸ—ï¸ Architecture

```
Browser                          Python Server (FastAPI)
â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
video element (src: file/webcam)
    â”‚
    â”‚ capture frame via <canvas>
    â”‚ encode â†’ JPEG â†’ base64
    â”‚ + cursor (x, y)
    â”‚ + clicked flag
    â”‚ + tunable params
    â”‚â”€â”€â”€â”€ WebSocket (JSON) â”€â”€â”€â”€â”€â”€â–º  Decode frame
                                    â”‚
                                    â”œâ”€ every N frames: YOLOv8 detect
                                    â”‚
                                    â”œâ”€ on click: pick_closest() â†’ CSRT.init()
                                    â”‚
                                    â”œâ”€ every frame: CSRT.update()
                                    â”‚   â””â”€ if lost â†’ re-detect
                                    â”‚
                                    â”œâ”€ every 3 frames: segmenter.get_mask()
                                    â”‚   â”œâ”€ person â†’ MediaPipe SelfieSegmentation
                                    â”‚   â””â”€ other  â†’ GrabCut
                                    â”‚
                                    â””â”€ renderer.render()
                                        â”œâ”€ Gaussian blur whole frame
                                        â”œâ”€ alpha-blend sharp subject via mask
                                        â”œâ”€ hover box (amber, dashed)
                                        â”œâ”€ lock box (green, animated)
                                        â””â”€ FPS / status HUD
                                    â”‚
    Decode base64 JPEG             â”‚
    draw on <canvas>    â—„â”€â”€â”€ WebSocket (JSON) â”€â”€â”€â”€ encode JPEG â†’ base64
    update sidebar HUD
```

### WebSocket message format

**Client â†’ Server**
```json
{
  "frame":         "<base64 JPEG>",
  "cursor_x":      320,
  "cursor_y":      240,
  "clicked":       true,
  "low_light":     false,
  "bokeh_k":       51,
  "detect_every":  15,
  "release":       false
}
```

**Server â†’ Client**
```json
{
  "frame":     "<base64 JPEG>",
  "tracking":  true,
  "label":     "person",
  "conf":      0.87,
  "fps":       24.3,
  "frame_id":  412,
  "det_count": 3
}
```

---

## âš¡ Performance Tips

| Goal | Setting |
|------|---------|
| Faster on slow CPU | Detect interval â†’ 30â€“60 |
| Better accuracy | Use `yolov8s.pt` (change in `app.py`) |
| Less network load | Lower JPEG quality in `app.py` (line `IMWRITE_JPEG_QUALITY, 82`) |
| Low-light scenes | Toggle "Low-light boost" in sidebar |

Expected FPS on modern hardware:
- CPU only: **18â€“26 FPS**
- GPU (RTX): **28â€“35 FPS**

---

## ğŸ› Troubleshooting

| Problem | Fix |
|---------|-----|
| `Connection refused` in browser | Make sure `python app.py` is running |
| Webcam not working | Check browser camera permissions |
| Low FPS | Increase detect interval slider to 30+ |
| Mask bleeds outside subject | Reduce `edge_blur_ksize` in `segmenter.py` |
| Server crashes on video | Install `opencv-contrib-python` not plain `opencv-python` |
| No module `mediapipe` | `pip install mediapipe` |

---

## ğŸ“œ License
MIT
